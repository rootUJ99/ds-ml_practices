{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.02\n",
    "EPOSCH = 5\n",
    "DOWNLOAD_MNIST = False\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data') or not os.listdir('./data'):\n",
    "    DOWNLOAD_MNIST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=DOWNLOAD_MNIST,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=DOWNLOAD_MNIST,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n",
      "torch.Size([50, 1, 28, 28]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for test, train in zip(train_loader, test_loader):\n",
    "    x0, y0 = test\n",
    "    x1, y1 = train\n",
    "    print(x0.shape, y0.shape)\n",
    "    print(x1.shape, y1.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=28,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.out = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        out, (x_, y_) = self.lstm(x, None)\n",
    "        output = self.out(out[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lstm): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm = Net()\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(lstm.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optim):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(dataloader):\n",
    "        x = x.view(-1, 28, 28)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            loss, current = loss.item(), step * len(x)\n",
    "            print( f'loss {loss:>7f} {current:>5d}/{size:>5d}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            x = x.view(-1, 28, 28)\n",
    "            y_pred = model(x)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f'test error \\n acc {(100*correct):>0.1f}% avg_loss {test_loss:>8f} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOSCH 1\n",
      "loss 2.298739     0/60000\n",
      "loss 0.659461  5000/60000\n",
      "loss 0.714092 10000/60000\n",
      "loss 0.293851 15000/60000\n",
      "loss 0.531091 20000/60000\n",
      "loss 0.148773 25000/60000\n",
      "loss 0.067063 30000/60000\n",
      "loss 0.366107 35000/60000\n",
      "loss 0.144693 40000/60000\n",
      "loss 0.362255 45000/60000\n",
      "loss 0.050549 50000/60000\n",
      "loss 0.182360 55000/60000\n",
      "test error \n",
      " acc 90.3% avg_loss 0.320079 \n",
      "\n",
      "EPOSCH 2\n",
      "loss 0.235053     0/60000\n",
      "loss 0.197910  5000/60000\n",
      "loss 0.439672 10000/60000\n",
      "loss 0.055559 15000/60000\n",
      "loss 0.246277 20000/60000\n",
      "loss 0.163662 25000/60000\n",
      "loss 0.166643 30000/60000\n",
      "loss 0.359554 35000/60000\n",
      "loss 0.145785 40000/60000\n",
      "loss 0.404661 45000/60000\n",
      "loss 0.030922 50000/60000\n",
      "loss 0.082342 55000/60000\n",
      "test error \n",
      " acc 93.3% avg_loss 0.220855 \n",
      "\n",
      "EPOSCH 3\n",
      "loss 0.243030     0/60000\n",
      "loss 0.193756  5000/60000\n",
      "loss 0.378277 10000/60000\n",
      "loss 0.018919 15000/60000\n",
      "loss 0.348544 20000/60000\n",
      "loss 0.069202 25000/60000\n",
      "loss 0.604330 30000/60000\n",
      "loss 0.630688 35000/60000\n",
      "loss 0.461461 40000/60000\n",
      "loss 1.069266 45000/60000\n",
      "loss 0.483957 50000/60000\n",
      "loss 0.640412 55000/60000\n",
      "test error \n",
      " acc 79.3% avg_loss 0.655593 \n",
      "\n",
      "EPOSCH 4\n",
      "loss 0.959859     0/60000\n",
      "loss 0.517159  5000/60000\n",
      "loss 0.621037 10000/60000\n",
      "loss 0.311786 15000/60000\n",
      "loss 0.485257 20000/60000\n",
      "loss 0.245740 25000/60000\n",
      "loss 0.351236 30000/60000\n",
      "loss 0.161673 35000/60000\n",
      "loss 0.239646 40000/60000\n",
      "loss 0.319576 45000/60000\n",
      "loss 0.197798 50000/60000\n",
      "loss 0.290427 55000/60000\n",
      "test error \n",
      " acc 88.0% avg_loss 0.398550 \n",
      "\n",
      "EPOSCH 5\n",
      "loss 0.440694     0/60000\n",
      "loss 0.364670  5000/60000\n",
      "loss 0.366336 10000/60000\n",
      "loss 0.219934 15000/60000\n",
      "loss 0.580984 20000/60000\n",
      "loss 0.955810 25000/60000\n",
      "loss 0.648315 30000/60000\n",
      "loss 0.514864 35000/60000\n",
      "loss 0.408027 40000/60000\n",
      "loss 0.881756 45000/60000\n",
      "loss 0.337457 50000/60000\n",
      "loss 0.250746 55000/60000\n",
      "test error \n",
      " acc 87.1% avg_loss 0.410524 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOSCH):\n",
    "    print(f'EPOSCH {i+1}')\n",
    "    train(train_loader, lstm, loss_fn, optim)\n",
    "    test(test_loader, lstm, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testx, testy = test_data[15][0], test_data[15][1]\n",
    "\n",
    "np_testx = testx[0].numpy()\n",
    "plt.imshow(np_testx)\n",
    "# testx = x.view(-1, 28, 28)\n",
    "test_pred_y = lstm(testx)\n",
    "argmax_pred_y = torch.argmax(test_pred_y)\n",
    "print(testy, argmax_pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
